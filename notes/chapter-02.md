# TDD: A First Example

- Incremental. One test at a time. Don't need all tests to start.
    - Pick next simplest behaviour. Most straightforward, smallest increment.
- But can record thoughts of upcoming tests in a "test list".
    - Code cleanup or refactor reminders go here also.
    - A personal memo, a rough note, a thought-dumping ground.
    - Does not constrain what you do and when you do it.
- Test names must be expressive. A sentence on what it verifies. Same for asserts.
- Three rules of TDD, from 'Uncle Bob' (Robert C. Martin)
    - Write production code only to make a failing test pass.
    - Write no more of a unit test than sufficient to fail. Includes compilation failures.
    - Write only the production code needed to pass the one failing test.
- Negative feedback (failure) is good. Ensures test honesty.
    - False positives are bad i.e. tests passing when they shouldn't.
- Seek incremental, immediate feedback. Test early and often. Safe coding.
    - Easy to debug when you know precisely what new code caused the failure.
    - Trade-off. Sometimes writing whole test clarifies interface design.
- Commit every time the 'code is green'. Known good states to roll back, if desired.
- Tests declare the behaviours your system should have.
    - Tests can be seen as specs. In fact, if crafted well, tests can be more concrete and comprehensive than specs.
    - Converse: any functionality not demanded by a test is bad.
    - This necessitates adding functionality that is only partial - even trivial or in breach of other specs - to start.
    - At each step, the source should only have the simplest generalized solution for what the set of tests needs.
- As we write more tests for more behaviours, will automatically self-correct then.
    - Think of TDD as if only one spec is being revealed at a time.
    - Building incrementally, *but* with "continually verified, forward progress".
    - TDD makes such progress possible in the face of incomplete or new information.
    - After adding new test and behaviour, a previous test may fail. This is good. Self-correction.
    - Increases speed in long run, avoiding errors from large, complex changes.
- We make decisions on design and implementation *as* we add tests.
- Be at peace with messy code. TDD saves a time and place to refactor.
    - Defer complexity that slows you down.
    - For example, put a new class and its test in same file. The interface design will keep changing as you test-drive.
- Don't neglect the "refactor" stage of TDD cycle.
    - Before the small messes add up, making any cleanup at all arduous.
    - Retain existing behaviour (as shown by the test) while improving design.
    - Some examples: eliminate hardcoding and code duplication; enhance test abstraction and expressiveness; make source code declarative
    - Declarative separates _interface_ (what) from _implementation_ (how). Clear, readable code. Clean, scalable designs.
    - Sometimes, can defer a cleanup if know the next test will 'drive' it out. But must guarantee that next step; make note in test list.
- Avoid prematurely optimizing during refactor (or green) stage.
    - Focus on correct behaviour, good design, consistent interfaces, expressive code.
    - Later, _maybe_, we optimize. But not without first _measuring_.
- Tests are independent.
    - Each test has its own separate context e.g. instance of object-under-test.
    - Each test deals with one precise behaviour. *Even if* two tests end up doing the same steps!
- Common setup or teardown in test 'fixture' or 'suite'
    - Keeps individual tests focused and clean. Highly abstracted, highly expressive.
    - Facilitates future maintenance by restricting potential changes to one place.
    - But common setup must re-run in each test. Recall each test has independent context.
- Each cycle, want to make 'green' by generalizing solution.
    - But don't _over-generalize_. Don't account for future concerns.
- TDD is not a science, it is a craft.
